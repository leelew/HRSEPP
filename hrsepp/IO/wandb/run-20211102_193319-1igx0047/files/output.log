Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 224, 224, 8) 0
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 224, 224, 71) 5183        input_1[0][0]
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 224, 224, 71) 45440       conv2d[0][0]
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 224, 224, 71) 284         conv2d_1[0][0]
__________________________________________________________________________________________________
max_pooling2d (MaxPooling2D)    (None, 112, 112, 71) 0           batch_normalization[0][0]
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 112, 112, 142 90880       max_pooling2d[0][0]
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 112, 112, 142 181618      conv2d_2[0][0]
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 112, 112, 142 568         conv2d_3[0][0]
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 142)  0           batch_normalization_1[0][0]
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 56, 56, 284)  363236      max_pooling2d_1[0][0]
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 56, 56, 284)  726188      conv2d_4[0][0]
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 56, 56, 284)  1136        conv2d_5[0][0]
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 284)  0           batch_normalization_2[0][0]
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 28, 28, 284)  726188      max_pooling2d_2[0][0]
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 28, 28, 284)  726188      conv2d_6[0][0]
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 28, 28, 284)  1136        conv2d_7[0][0]
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 284)  0           batch_normalization_3[0][0]
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 14, 14, 568)  1452376     max_pooling2d_3[0][0]
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 14, 14, 568)  2904184     conv2d_8[0][0]
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 14, 14, 568)  2272        conv2d_9[0][0]
__________________________________________________________________________________________________
up_sampling2d (UpSampling2D)    (None, 28, 28, 568)  0           batch_normalization_4[0][0]
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 28, 28, 284)  645532      up_sampling2d[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 28, 28, 568)  0           batch_normalization_3[0][0]
                                                                 conv2d_10[0][0]
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 28, 28, 284)  1452092     concatenate[0][0]
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 28, 28, 284)  726188      conv2d_11[0][0]
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 28, 28, 284)  1136        conv2d_12[0][0]
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 284)  0           batch_normalization_5[0][0]
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 56, 56, 284)  322908      up_sampling2d_1[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 56, 56, 568)  0           batch_normalization_2[0][0]
                                                                 conv2d_13[0][0]
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 56, 56, 284)  1452092     concatenate_1[0][0]
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 56, 56, 284)  726188      conv2d_14[0][0]
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 56, 56, 284)  1136        conv2d_15[0][0]
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 112, 112, 284 0           batch_normalization_6[0][0]
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 112, 112, 142 161454      up_sampling2d_2[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 112, 112, 284 0           batch_normalization_1[0][0]
                                                                 conv2d_16[0][0]
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 112, 112, 142 363094      concatenate_2[0][0]
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 112, 112, 142 181618      conv2d_17[0][0]
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 112, 112, 142 568         conv2d_18[0][0]
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 142 0           batch_normalization_7[0][0]
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 224, 224, 71) 40399       up_sampling2d_3[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 224, 224, 142 0           conv2d_1[0][0]
                                                                 conv2d_19[0][0]
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 224, 224, 71) 90809       concatenate_3[0][0]
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 224, 224, 71) 45440       conv2d_20[0][0]
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 224, 224, 71) 45440       conv2d_21[0][0]
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 224, 224, 1)  72          conv2d_22[0][0]
__________________________________________________________________________________________________
tf.stack (TFOpLambda)           (None, 1, 224, 224,  0           conv2d_23[0][0]
==================================================================================================
Total params: 13,483,043
Trainable params: 13,478,925
Non-trainable params: 4,118
__________________________________________________________________________________________________
2021-11-02 19:33:26.335396: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-11-02 19:33:26.336102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-11-02 19:33:26.386609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-11-02 19:33:26.387059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:65:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-11-02 19:33:26.387082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-11-02 19:33:26.388888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-11-02 19:33:26.388956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-11-02 19:33:26.389610: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-11-02 19:33:26.389786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-11-02 19:33:26.391318: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-11-02 19:33:26.391713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-11-02 19:33:26.391831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-11-02 19:33:26.393480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-11-02 19:33:26.393862: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-02 19:33:26.395017: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-11-02 19:33:26.694983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-11-02 19:33:26.695404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:65:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.62GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2021-11-02 19:33:26.695429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-11-02 19:33:26.695471: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-11-02 19:33:26.695482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-11-02 19:33:26.695493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-11-02 19:33:26.695504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-11-02 19:33:26.695514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-11-02 19:33:26.695525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2021-11-02 19:33:26.695536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-11-02 19:33:26.697044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2021-11-02 19:33:26.697072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2021-11-02 19:33:27.355693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-11-02 19:33:27.355732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2021-11-02 19:33:27.355738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N
2021-11-02 19:33:27.355742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N
2021-11-02 19:33:27.357447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10071 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2021-11-02 19:33:27.358574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10020 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)
Epoch 1/50
2021-11-02 19:33:29.816463: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2021-11-02 19:33:29.836409: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3699850000 Hz
2021-11-02 19:33:30.959606: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-11-02 19:33:32.248440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2021-11-02 19:33:32.608300: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11



















92/92 [==============================] - 54s 491ms/step - loss: 0.9847 - val_loss: 0.0039
Epoch 2/50



















92/92 [==============================] - 39s 429ms/step - loss: 0.0021 - val_loss: 0.0022
Epoch 3/50



















92/92 [==============================] - 40s 432ms/step - loss: 0.0016 - val_loss: 0.0017
Epoch 4/50



















92/92 [==============================] - 40s 435ms/step - loss: 0.0015 - val_loss: 0.0015
Epoch 5/50



















92/92 [==============================] - 40s 436ms/step - loss: 0.0013 - val_loss: 0.0012
Epoch 6/50



















92/92 [==============================] - 40s 437ms/step - loss: 0.0012 - val_loss: 0.0012
Epoch 7/50



















92/92 [==============================] - 40s 438ms/step - loss: 0.0012 - val_loss: 0.0010
Epoch 8/50



















92/92 [==============================] - 40s 439ms/step - loss: 0.0010 - val_loss: 8.7541e-04
Epoch 9/50



















92/92 [==============================] - 40s 439ms/step - loss: 9.9694e-04 - val_loss: 9.3339e-04
Epoch 10/50



















92/92 [==============================] - 40s 439ms/step - loss: 9.8337e-04 - val_loss: 7.9058e-04
Epoch 11/50


















92/92 [==============================] - 40s 440ms/step - loss: 8.8909e-04 - val_loss: 7.6139e-04
Epoch 12/50



















92/92 [==============================] - 40s 439ms/step - loss: 8.2238e-04 - val_loss: 8.8682e-04
Epoch 13/50



















92/92 [==============================] - 40s 440ms/step - loss: 8.2280e-04 - val_loss: 7.6800e-04
Epoch 14/50



















92/92 [==============================] - 40s 440ms/step - loss: 7.8562e-04 - val_loss: 6.8907e-04
Epoch 15/50



















92/92 [==============================] - 40s 440ms/step - loss: 7.4886e-04 - val_loss: 8.0331e-04
Epoch 16/50



















92/92 [==============================] - 40s 440ms/step - loss: 8.4344e-04 - val_loss: 6.3553e-04
Epoch 17/50


















92/92 [==============================] - 40s 440ms/step - loss: 7.5832e-04 - val_loss: 6.4352e-04
Epoch 18/50


















92/92 [==============================] - 40s 440ms/step - loss: 7.0099e-04 - val_loss: 6.4825e-04
Epoch 19/50



















92/92 [==============================] - 40s 440ms/step - loss: 6.9229e-04 - val_loss: 6.3954e-04
Epoch 20/50



















92/92 [==============================] - 40s 440ms/step - loss: 6.8056e-04 - val_loss: 7.1816e-04
Epoch 21/50


















92/92 [==============================] - 40s 439ms/step - loss: 7.7429e-04 - val_loss: 6.2154e-04
Epoch 22/50


















92/92 [==============================] - 40s 439ms/step - loss: 7.1217e-04 - val_loss: 6.3528e-04
Epoch 23/50


















92/92 [==============================] - 41s 442ms/step - loss: 7.0963e-04 - val_loss: 6.9060e-04
Epoch 24/50



















92/92 [==============================] - 40s 440ms/step - loss: 7.5841e-04 - val_loss: 6.7487e-04
Epoch 25/50



















92/92 [==============================] - 40s 440ms/step - loss: 7.0447e-04 - val_loss: 6.4468e-04
Epoch 26/50



















92/92 [==============================] - 40s 439ms/step - loss: 6.9277e-04 - val_loss: 9.8106e-04
Epoch 27/50



















92/92 [==============================] - 40s 439ms/step - loss: 7.2260e-04 - val_loss: 5.6945e-04
Epoch 28/50


















92/92 [==============================] - 40s 440ms/step - loss: 6.6412e-04 - val_loss: 6.6947e-04
Epoch 29/50



















92/92 [==============================] - 40s 440ms/step - loss: 6.2823e-04 - val_loss: 7.2244e-04
Epoch 30/50



















92/92 [==============================] - 40s 440ms/step - loss: 7.1875e-04 - val_loss: 6.8442e-04
Epoch 31/50



















92/92 [==============================] - 40s 440ms/step - loss: 6.4283e-04 - val_loss: 5.8593e-04
Epoch 32/50



















92/92 [==============================] - 40s 440ms/step - loss: 6.2748e-04 - val_loss: 6.4523e-04
Epoch 33/50


















92/92 [==============================] - 40s 439ms/step - loss: 6.4839e-04 - val_loss: 5.9984e-04
Epoch 34/50


















92/92 [==============================] - 40s 439ms/step - loss: 5.8833e-04 - val_loss: 8.0809e-04
Epoch 35/50


















92/92 [==============================] - 40s 440ms/step - loss: 6.4957e-04 - val_loss: 5.4098e-04
Epoch 36/50



















92/92 [==============================] - 40s 439ms/step - loss: 6.0475e-04 - val_loss: 5.8770e-04
Epoch 37/50



















92/92 [==============================] - 40s 439ms/step - loss: 6.3729e-04 - val_loss: 6.2278e-04
Epoch 38/50



















92/92 [==============================] - 40s 439ms/step - loss: 5.9969e-04 - val_loss: 6.0269e-04
Epoch 39/50


















92/92 [==============================] - 40s 439ms/step - loss: 5.7832e-04 - val_loss: 7.3697e-04
Epoch 40/50


















92/92 [==============================] - 40s 439ms/step - loss: 5.5430e-04 - val_loss: 8.2473e-04
Epoch 41/50


















92/92 [==============================] - 40s 439ms/step - loss: 5.8750e-04 - val_loss: 6.0088e-04
Epoch 42/50



















92/92 [==============================] - 40s 439ms/step - loss: 5.6161e-04 - val_loss: 5.8513e-04
Epoch 43/50



















92/92 [==============================] - 40s 439ms/step - loss: 5.8966e-04 - val_loss: 6.7345e-04
Epoch 44/50



















92/92 [==============================] - 40s 439ms/step - loss: 5.7237e-04 - val_loss: 6.1379e-04
Epoch 45/50



















92/92 [==============================] - 40s 439ms/step - loss: 5.8091e-04 - val_loss: 5.4618e-04
Epoch 46/50


















92/92 [==============================] - 40s 439ms/step - loss: 5.2389e-04 - val_loss: 6.8030e-04
Epoch 47/50


















92/92 [==============================] - 40s 439ms/step - loss: 5.6668e-04 - val_loss: 6.3960e-04
Epoch 48/50



















92/92 [==============================] - 40s 439ms/step - loss: 5.2786e-04 - val_loss: 0.0011
Epoch 49/50



















92/92 [==============================] - 40s 439ms/step - loss: 6.4455e-04 - val_loss: 6.8532e-04
Epoch 50/50




















92/92 [==============================] - 40s 439ms/step - loss: 5.9376e-04 - val_loss: 6.2937e-04
2021-11-02 20:07:22.148476: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2928672768 exceeds 10% of free system memory.
2021-11-02 20:07:51.454723: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.